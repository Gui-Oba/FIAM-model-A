{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50f6a97d",
   "metadata": {},
   "source": [
    "# XGBoost Expanding-Window Forecast\n",
    "\n",
    "Train an XGBoost regressor on the processed parquet panel using an expanding-window setup, and report out-of-sample R² following Gu et al. (2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c7eea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T19:20:40.278135Z",
     "iopub.status.busy": "2025-10-05T19:20:40.277941Z",
     "iopub.status.idle": "2025-10-05T19:20:45.649162Z",
     "shell.execute_reply": "2025-10-05T19:20:45.648496Z",
     "shell.execute_reply.started": "2025-10-05T19:20:40.278119Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 51 candidate features.\n",
      "Excluded non-numeric or redundant features: ['excntry', 'gvkey', 'id', 'iid', 'month', 'stock_ret', 'year']\n",
      "Using 44 numeric features.\n",
      "CuPy detected: using GPU-backed arrays for XGBoost.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "from pandas.tseries.offsets import MonthEnd, DateOffset\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBRegressor\n",
    "try:\n",
    "    import cupy as cp\n",
    "    HAS_CUPY = cp.cuda.runtime.getDeviceCount() > 0\n",
    "except Exception:\n",
    "    cp = None\n",
    "    HAS_CUPY = False\n",
    "\n",
    "DATA_ROOT = Path(\"/\")\n",
    "RET_DATA_PATH = Path(\"/ret_parquet\")\n",
    "FEATURE_LIST_PATH = Path(\"column_names.txt\")\n",
    "TARGET = \"stock_ret\"\n",
    "ID_COLUMNS = [\"gvkey\", \"iid\", \"excntry\", \"year\", \"month\"]\n",
    "\n",
    "if not DATA_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"Parquet directory not found: {DATA_ROOT}\")\n",
    "\n",
    "if not RET_DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Return parquet path not found: {RET_DATA_PATH}\")\n",
    "\n",
    "raw_feature_names = [line.strip() for line in FEATURE_LIST_PATH.read_text().splitlines() if line.strip()]\n",
    "print(f\"Loaded {len(raw_feature_names)} candidate features.\")\n",
    "\n",
    "dataset = ds.dataset(str(DATA_ROOT), format=\"parquet\", partitioning=\"hive\")\n",
    "schema = dataset.schema\n",
    "\n",
    "feature_names = []\n",
    "dropped_features = []\n",
    "for name in raw_feature_names:\n",
    "    if name in ID_COLUMNS or name == TARGET:\n",
    "        dropped_features.append(name)\n",
    "        continue\n",
    "    if name not in schema.names:\n",
    "        dropped_features.append(name)\n",
    "        continue\n",
    "    field_type = schema.field(name).type\n",
    "    if pa.types.is_floating(field_type) or pa.types.is_integer(field_type):\n",
    "        feature_names.append(name)\n",
    "    else:\n",
    "        dropped_features.append(name)\n",
    "\n",
    "if dropped_features:\n",
    "    print(f\"Excluded non-numeric or redundant features: {sorted(set(dropped_features))}\")\n",
    "print(f\"Using {len(feature_names)} numeric features.\")\n",
    "if HAS_CUPY:\n",
    "    print(\"CuPy detected: using GPU-backed arrays for XGBoost.\")\n",
    "else:\n",
    "    print(\"CuPy unavailable; XGBoost will copy NumPy arrays to the GPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3002136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T19:20:45.650310Z",
     "iopub.status.busy": "2025-10-05T19:20:45.649890Z",
     "iopub.status.idle": "2025-10-05T19:21:16.395652Z",
     "shell.execute_reply": "2025-10-05T19:21:16.395022Z",
     "shell.execute_reply.started": "2025-10-05T19:20:45.650289Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Dropped -848 feature rows when merging with returns.\n",
      "Panel rows: 6,402,262\n",
      "Monthly slices: 245\n",
      "Date range: 2005-02-28 to 2025-06-30\n"
     ]
    }
   ],
   "source": [
    "feature_columns = feature_names + ID_COLUMNS\n",
    "feature_table = dataset.to_table(columns=feature_columns)\n",
    "features_df = feature_table.to_pandas()\n",
    "\n",
    "if RET_DATA_PATH.is_dir():\n",
    "    returns_dataset = ds.dataset(str(RET_DATA_PATH), format=\"parquet\", partitioning=\"hive\")\n",
    "else:\n",
    "    returns_dataset = ds.dataset(str(RET_DATA_PATH), format=\"parquet\")\n",
    "\n",
    "returns_table = returns_dataset.to_table(columns=ID_COLUMNS + [TARGET])\n",
    "returns_df = returns_table.to_pandas()\n",
    "\n",
    "for df in (features_df, returns_df):\n",
    "    df['year'] = df['year'].astype(int)\n",
    "    df['month'] = df['month'].astype(int)\n",
    "    df['gvkey'] = df['gvkey'].astype(str).str.strip()\n",
    "    df['iid'] = df['iid'].astype(str).str.strip()\n",
    "    df['excntry'] = df['excntry'].astype(str).str.strip()\n",
    "\n",
    "panel_df = features_df.merge(returns_df, on=ID_COLUMNS, how='inner')\n",
    "rows_dropped = len(features_df) - len(panel_df)\n",
    "if rows_dropped:\n",
    "    print(f\"Warning: Dropped {rows_dropped} feature rows when merging with returns.\")\n",
    "\n",
    "panel_df['obs_date'] = pd.to_datetime({'year': panel_df['year'], 'month': panel_df['month'], 'day': 1}) + MonthEnd(0)\n",
    "panel_df = panel_df.sort_values(['obs_date', 'gvkey', 'iid']).reset_index(drop=True)\n",
    "\n",
    "panel_df[feature_names] = panel_df[feature_names].astype(np.float32)\n",
    "panel_df[TARGET] = panel_df[TARGET].astype(np.float32)\n",
    "\n",
    "n_months = panel_df['obs_date'].nunique()\n",
    "print(f\"Panel rows: {len(panel_df):,}\")\n",
    "print(f\"Monthly slices: {n_months}\")\n",
    "print(f\"Date range: {panel_df['obs_date'].min().date()} to {panel_df['obs_date'].max().date()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bb86420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T19:21:16.397876Z",
     "iopub.status.busy": "2025-10-05T19:21:16.397262Z",
     "iopub.status.idle": "2025-10-05T19:22:11.909993Z",
     "shell.execute_reply": "2025-10-05T19:22:11.909320Z",
     "shell.execute_reply.started": "2025-10-05T19:21:16.397827Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning: 6,402,262 rows across 245 months.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36/1567063119.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  panel_df = panel_df.groupby('obs_date', group_keys=False).apply(_cross_sectional_scale).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied cross-sectional median fill, ranking, and scaling per month.\n"
     ]
    }
   ],
   "source": [
    "def _prepare(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    return df.dropna(subset=[TARGET])\n",
    "\n",
    "panel_df = _prepare(panel_df)\n",
    "valid_features = [col for col in feature_names if not panel_df[col].isna().all()]\n",
    "removed_all_nan = sorted(set(feature_names) - set(valid_features))\n",
    "feature_names = valid_features\n",
    "print(f\"After cleaning: {len(panel_df):,} rows across {panel_df['obs_date'].nunique()} months.\")\n",
    "if removed_all_nan:\n",
    "    print(f\"Dropped all-NaN features: {removed_all_nan}\")\n",
    "\n",
    "def _cross_sectional_scale(group: pd.DataFrame) -> pd.DataFrame:\n",
    "    feats = group[feature_names]\n",
    "    medians = feats.median(skipna=True)\n",
    "    filled = feats.fillna(medians)\n",
    "    ranks = filled.rank(method=\"dense\") - 1.0\n",
    "    max_rank = ranks.max()\n",
    "    denom = max_rank.replace(0.0, np.nan)\n",
    "    scaled = ranks.divide(denom, axis=1) * 2.0 - 1.0\n",
    "    scaled = scaled.fillna(0.0).clip(-1.0, 1.0).astype(np.float32)\n",
    "    group = group.copy()\n",
    "    group[feature_names] = scaled\n",
    "    return group\n",
    "\n",
    "panel_df = panel_df.groupby('obs_date', group_keys=False).apply(_cross_sectional_scale).reset_index(drop=True)\n",
    "print('Applied cross-sectional median fill, ranking, and scaling per month.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f7767c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T19:22:11.911009Z",
     "iopub.status.busy": "2025-10-05T19:22:11.910735Z",
     "iopub.status.idle": "2025-10-05T19:31:22.856466Z",
     "shell.execute_reply": "2025-10-05T19:31:22.855868Z",
     "shell.execute_reply.started": "2025-10-05T19:22:11.910990Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 11 expanding-window fits.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>train_rows</th>\n",
       "      <th>val_rows</th>\n",
       "      <th>test_rows</th>\n",
       "      <th>train_months</th>\n",
       "      <th>val_months</th>\n",
       "      <th>test_months</th>\n",
       "      <th>train_end</th>\n",
       "      <th>val_end</th>\n",
       "      <th>test_start</th>\n",
       "      <th>...</th>\n",
       "      <th>xgb_best_iteration</th>\n",
       "      <th>xgb_val_rmse</th>\n",
       "      <th>xgb_params</th>\n",
       "      <th>xgb_oos_r2</th>\n",
       "      <th>ridge_alpha</th>\n",
       "      <th>ridge_val_mse</th>\n",
       "      <th>ridge_oos_r2</th>\n",
       "      <th>xgb_sse</th>\n",
       "      <th>ridge_sse</th>\n",
       "      <th>tss_zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2322368</td>\n",
       "      <td>590373</td>\n",
       "      <td>300463</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.340126</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'n_estimator...</td>\n",
       "      <td>6.048177e-06</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.115751</td>\n",
       "      <td>1.016891e-05</td>\n",
       "      <td>3.009153e+07</td>\n",
       "      <td>3.009140e+07</td>\n",
       "      <td>3.009171e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2616117</td>\n",
       "      <td>597087</td>\n",
       "      <td>304285</td>\n",
       "      <td>107</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>7.101045</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'n_estimator...</td>\n",
       "      <td>6.578513e-03</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50.424767</td>\n",
       "      <td>5.052175e-03</td>\n",
       "      <td>1.573424e+04</td>\n",
       "      <td>1.575842e+04</td>\n",
       "      <td>1.583844e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2912741</td>\n",
       "      <td>604748</td>\n",
       "      <td>311854</td>\n",
       "      <td>119</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>239</td>\n",
       "      <td>7.055818</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'n_estimator...</td>\n",
       "      <td>9.742561e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>49.784599</td>\n",
       "      <td>1.505668e-06</td>\n",
       "      <td>9.032524e+07</td>\n",
       "      <td>9.032519e+07</td>\n",
       "      <td>9.032533e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3213204</td>\n",
       "      <td>616139</td>\n",
       "      <td>318822</td>\n",
       "      <td>131</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12.108843</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'n_estimator...</td>\n",
       "      <td>-2.585214e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>146.623978</td>\n",
       "      <td>-1.618490e-04</td>\n",
       "      <td>6.867743e+05</td>\n",
       "      <td>6.867079e+05</td>\n",
       "      <td>6.865968e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3517489</td>\n",
       "      <td>630676</td>\n",
       "      <td>323546</td>\n",
       "      <td>143</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12.012839</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'n_estimator...</td>\n",
       "      <td>2.100727e-05</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>144.308350</td>\n",
       "      <td>5.057307e-05</td>\n",
       "      <td>6.426210e+06</td>\n",
       "      <td>6.426020e+06</td>\n",
       "      <td>6.426346e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3829343</td>\n",
       "      <td>642368</td>\n",
       "      <td>327566</td>\n",
       "      <td>155</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.327628</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'n_estimator...</td>\n",
       "      <td>1.472808e-03</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>11.073408</td>\n",
       "      <td>1.257200e-03</td>\n",
       "      <td>1.463896e+05</td>\n",
       "      <td>1.464212e+05</td>\n",
       "      <td>1.466055e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>4148165</td>\n",
       "      <td>651112</td>\n",
       "      <td>347252</td>\n",
       "      <td>167</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.177211</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'n_estimator...</td>\n",
       "      <td>7.970717e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>10.094513</td>\n",
       "      <td>5.313812e-07</td>\n",
       "      <td>1.445289e+09</td>\n",
       "      <td>1.445289e+09</td>\n",
       "      <td>1.445290e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>4471711</td>\n",
       "      <td>674818</td>\n",
       "      <td>363572</td>\n",
       "      <td>179</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>46.281355</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'n_estimator...</td>\n",
       "      <td>5.377292e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2141.964355</td>\n",
       "      <td>3.840923e-07</td>\n",
       "      <td>8.331326e+08</td>\n",
       "      <td>8.331327e+08</td>\n",
       "      <td>8.331331e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4799277</td>\n",
       "      <td>710824</td>\n",
       "      <td>365229</td>\n",
       "      <td>191</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>56.615591</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'n_estimator...</td>\n",
       "      <td>-1.051233e-06</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3205.325195</td>\n",
       "      <td>-1.051233e-06</td>\n",
       "      <td>8.371128e+07</td>\n",
       "      <td>8.371128e+07</td>\n",
       "      <td>8.371119e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5146529</td>\n",
       "      <td>728801</td>\n",
       "      <td>362386</td>\n",
       "      <td>203</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35.468535</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'n_estimator...</td>\n",
       "      <td>-1.009490e-06</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1258.024292</td>\n",
       "      <td>6.056938e-06</td>\n",
       "      <td>2.852930e+08</td>\n",
       "      <td>2.852909e+08</td>\n",
       "      <td>2.852927e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5510101</td>\n",
       "      <td>727615</td>\n",
       "      <td>164546</td>\n",
       "      <td>215</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>22.519784</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'n_estimator...</td>\n",
       "      <td>-7.909385e-05</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>507.130096</td>\n",
       "      <td>5.605346e-05</td>\n",
       "      <td>8.724504e+06</td>\n",
       "      <td>8.723325e+06</td>\n",
       "      <td>8.723814e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration  train_rows  val_rows  test_rows  train_months  val_months  \\\n",
       "0           0     2322368    590373     300463            95          24   \n",
       "1           1     2616117    597087     304285           107          24   \n",
       "2           2     2912741    604748     311854           119          24   \n",
       "3           3     3213204    616139     318822           131          24   \n",
       "4           4     3517489    630676     323546           143          24   \n",
       "5           5     3829343    642368     327566           155          24   \n",
       "6           6     4148165    651112     347252           167          24   \n",
       "7           7     4471711    674818     363572           179          24   \n",
       "8           8     4799277    710824     365229           191          24   \n",
       "9           9     5146529    728801     362386           203          24   \n",
       "10         10     5510101    727615     164546           215          24   \n",
       "\n",
       "    test_months   train_end     val_end  test_start  ... xgb_best_iteration  \\\n",
       "0            12  2012-12-31  2014-12-31  2015-01-01  ...                  1   \n",
       "1            12  2013-12-31  2015-12-31  2016-01-01  ...                 45   \n",
       "2            12  2014-12-31  2016-12-31  2017-01-01  ...                239   \n",
       "3            12  2015-12-31  2017-12-31  2018-01-01  ...                  0   \n",
       "4            12  2016-12-31  2018-12-31  2019-01-01  ...                  0   \n",
       "5            12  2017-12-31  2019-12-31  2020-01-01  ...                  0   \n",
       "6            12  2018-12-31  2020-12-31  2021-01-01  ...                  0   \n",
       "7            12  2019-12-31  2021-12-31  2022-01-01  ...                  0   \n",
       "8            12  2020-12-31  2022-12-31  2023-01-01  ...                  0   \n",
       "9            12  2021-12-31  2023-12-31  2024-01-01  ...                  0   \n",
       "10            6  2022-12-31  2024-12-31  2025-01-01  ...                  0   \n",
       "\n",
       "    xgb_val_rmse                                         xgb_params  \\\n",
       "0       0.340126  {'objective': 'reg:squarederror', 'n_estimator...   \n",
       "1       7.101045  {'objective': 'reg:squarederror', 'n_estimator...   \n",
       "2       7.055818  {'objective': 'reg:squarederror', 'n_estimator...   \n",
       "3      12.108843  {'objective': 'reg:squarederror', 'n_estimator...   \n",
       "4      12.012839  {'objective': 'reg:squarederror', 'n_estimator...   \n",
       "5       3.327628  {'objective': 'reg:squarederror', 'n_estimator...   \n",
       "6       3.177211  {'objective': 'reg:squarederror', 'n_estimator...   \n",
       "7      46.281355  {'objective': 'reg:squarederror', 'n_estimator...   \n",
       "8      56.615591  {'objective': 'reg:squarederror', 'n_estimator...   \n",
       "9      35.468535  {'objective': 'reg:squarederror', 'n_estimator...   \n",
       "10     22.519784  {'objective': 'reg:squarederror', 'n_estimator...   \n",
       "\n",
       "      xgb_oos_r2  ridge_alpha ridge_val_mse  ridge_oos_r2       xgb_sse  \\\n",
       "0   6.048177e-06       0.0001      0.115751  1.016891e-05  3.009153e+07   \n",
       "1   6.578513e-03       0.0001     50.424767  5.052175e-03  1.573424e+04   \n",
       "2   9.742561e-07       0.0001     49.784599  1.505668e-06  9.032524e+07   \n",
       "3  -2.585214e-04       0.0001    146.623978 -1.618490e-04  6.867743e+05   \n",
       "4   2.100727e-05       0.0001    144.308350  5.057307e-05  6.426210e+06   \n",
       "5   1.472808e-03       0.0001     11.073408  1.257200e-03  1.463896e+05   \n",
       "6   7.970717e-07       0.0001     10.094513  5.313812e-07  1.445289e+09   \n",
       "7   5.377292e-07       0.0001   2141.964355  3.840923e-07  8.331326e+08   \n",
       "8  -1.051233e-06       0.0001   3205.325195 -1.051233e-06  8.371128e+07   \n",
       "9  -1.009490e-06       0.0001   1258.024292  6.056938e-06  2.852930e+08   \n",
       "10 -7.909385e-05       0.0001    507.130096  5.605346e-05  8.724504e+06   \n",
       "\n",
       "       ridge_sse      tss_zero  \n",
       "0   3.009140e+07  3.009171e+07  \n",
       "1   1.575842e+04  1.583844e+04  \n",
       "2   9.032519e+07  9.032533e+07  \n",
       "3   6.867079e+05  6.865968e+05  \n",
       "4   6.426020e+06  6.426346e+06  \n",
       "5   1.464212e+05  1.466055e+05  \n",
       "6   1.445289e+09  1.445290e+09  \n",
       "7   8.331327e+08  8.331331e+08  \n",
       "8   8.371128e+07  8.371119e+07  \n",
       "9   2.852909e+08  2.852927e+08  \n",
       "10  8.723325e+06  8.723814e+06  \n",
       "\n",
       "[11 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_START = pd.Timestamp('2005-01-01')\n",
    "TRAIN_YEARS = 8\n",
    "VAL_YEARS = 2\n",
    "TEST_YEARS = 1\n",
    "\n",
    "OUTPUT_ROOT = Path('oos_preds_pca')\n",
    "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "PCA_VARIANCE = 0.95\n",
    "\n",
    "PARAM_GRID = [\n",
    "    {\"max_depth\": 4, \"min_child_weight\": 5, \"subsample\": 0.90, \"colsample_bytree\": 0.80, \"reg_lambda\": 1.0, \"gamma\": 0.0},\n",
    "    {\"max_depth\": 5, \"min_child_weight\": 10, \"subsample\": 0.85, \"colsample_bytree\": 0.75, \"reg_lambda\": 1.5, \"gamma\": 0.0},\n",
    "    {\"max_depth\": 6, \"min_child_weight\": 15, \"subsample\": 0.80, \"colsample_bytree\": 0.70, \"reg_lambda\": 2.0, \"gamma\": 0.1},\n",
    "    {\"max_depth\": 3, \"min_child_weight\": 20, \"subsample\": 0.95, \"colsample_bytree\": 0.85, \"reg_lambda\": 1.0, \"gamma\": 0.0},\n",
    "]\n",
    "\n",
    "RIDGE_ALPHAS = [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 0.5, 1.0, 5.0]\n",
    "\n",
    "max_date = panel_df['obs_date'].max()\n",
    "predictions_by_month = []\n",
    "window_summaries = []\n",
    "\n",
    "counter = 0\n",
    "while True:\n",
    "    train_start = TRAIN_START\n",
    "    train_end = train_start + DateOffset(years=TRAIN_YEARS + counter)\n",
    "    val_start = train_end\n",
    "    val_end = val_start + DateOffset(years=VAL_YEARS)\n",
    "    test_start = val_end\n",
    "    test_end = test_start + DateOffset(years=TEST_YEARS)\n",
    "\n",
    "    if val_start > max_date or test_start > max_date:\n",
    "        break\n",
    "\n",
    "    mask_train = (panel_df['obs_date'] >= train_start) & (panel_df['obs_date'] < train_end)\n",
    "    mask_val = (panel_df['obs_date'] >= val_start) & (panel_df['obs_date'] < val_end)\n",
    "    mask_test = (panel_df['obs_date'] >= test_start) & (panel_df['obs_date'] < test_end)\n",
    "\n",
    "    if mask_test.sum() == 0:\n",
    "        break\n",
    "    if mask_train.sum() == 0 or mask_val.sum() == 0:\n",
    "        counter += 1\n",
    "        continue\n",
    "\n",
    "    X_train = panel_df.loc[mask_train, feature_names]\n",
    "    y_train = panel_df.loc[mask_train, TARGET]\n",
    "    X_val = panel_df.loc[mask_val, feature_names]\n",
    "    y_val = panel_df.loc[mask_val, TARGET]\n",
    "    X_test = panel_df.loc[mask_test, feature_names]\n",
    "    y_test = panel_df.loc[mask_test, TARGET]\n",
    "\n",
    "    feature_scaler = StandardScaler()\n",
    "    X_train_scaled = feature_scaler.fit_transform(X_train)\n",
    "    X_val_scaled = feature_scaler.transform(X_val)\n",
    "    X_test_scaled = feature_scaler.transform(X_test)\n",
    "\n",
    "    pca = PCA(n_components=PCA_VARIANCE, svd_solver='full')\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_val_pca = pca.transform(X_val_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    component_scaler = StandardScaler()\n",
    "    X_train_ready = component_scaler.fit_transform(X_train_pca)\n",
    "    X_val_ready = component_scaler.transform(X_val_pca)\n",
    "    X_test_ready = component_scaler.transform(X_test_pca)\n",
    "\n",
    "    X_train_ready = X_train_ready.astype(np.float32)\n",
    "    X_val_ready = X_val_ready.astype(np.float32)\n",
    "    X_test_ready = X_test_ready.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "    y_train_np = y_train.to_numpy(dtype=np.float32)\n",
    "    y_val_np = y_val.to_numpy(dtype=np.float32)\n",
    "    y_test_np = y_test.to_numpy(dtype=np.float32)\n",
    "\n",
    "    if HAS_CUPY:\n",
    "        X_train_xgb = cp.asarray(X_train_ready)\n",
    "        X_val_xgb = cp.asarray(X_val_ready)\n",
    "        X_test_xgb = cp.asarray(X_test_ready)\n",
    "        y_train_xgb = cp.asarray(y_train_np)\n",
    "        y_val_xgb = cp.asarray(y_val_np)\n",
    "        y_test_xgb = cp.asarray(y_test_np)\n",
    "    else:\n",
    "        X_train_xgb = X_train_ready\n",
    "        X_val_xgb = X_val_ready\n",
    "        X_test_xgb = X_test_ready\n",
    "        y_train_xgb = y_train_np\n",
    "        y_val_xgb = y_val_np\n",
    "        y_test_xgb = y_test_np\n",
    "\n",
    "    pca_components = int(pca.n_components_)\n",
    "    pca_var = float(pca.explained_variance_ratio_.sum())\n",
    "\n",
    "    base_params = dict(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.05,\n",
    "        device=\"cuda\",\n",
    "        tree_method='hist',\n",
    "        missing=np.nan,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        eval_metric='rmse',\n",
    "        early_stopping_rounds=75,\n",
    "    )\n",
    "\n",
    "    best_model = None\n",
    "    best_params = None\n",
    "    best_val_rmse = float('inf')\n",
    "    for trial in PARAM_GRID:\n",
    "        trial_params = dict(base_params)\n",
    "        trial_params.update(trial)\n",
    "        trial_model = XGBRegressor(**trial_params)\n",
    "        trial_model.fit(X_train_xgb, y_train_xgb, eval_set=[(X_val_xgb, y_val_xgb)], verbose=False)\n",
    "        score = float(getattr(trial_model, 'best_score', np.inf))\n",
    "        if score < best_val_rmse:\n",
    "            best_val_rmse = score\n",
    "            best_params = {k: (float(v) if isinstance(v, (np.floating, np.float32)) else v) for k, v in trial_params.items()}\n",
    "            best_model = trial_model\n",
    "\n",
    "    if best_model is None:\n",
    "        counter += 1\n",
    "        continue\n",
    "\n",
    "    y_pred = best_model.predict(X_test_xgb)\n",
    "    if HAS_CUPY and cp is not None and isinstance(y_pred, cp.ndarray):\n",
    "        y_pred = cp.asnumpy(y_pred)\n",
    "    errors = y_test_np - y_pred\n",
    "    sse = float(np.square(errors).sum())\n",
    "    tss_zero = float(np.square(y_test_np).sum())\n",
    "    r2_oos = 1.0 - sse / tss_zero if tss_zero > 0 else float('nan')\n",
    "\n",
    "    best_ridge_model = None\n",
    "    best_ridge_alpha = None\n",
    "    best_ridge_val_mse = float('inf')\n",
    "    for alpha in RIDGE_ALPHAS:\n",
    "        ridge = Ridge(alpha=alpha, fit_intercept=True, solver='svd')\n",
    "        ridge.fit(X_train_ready, y_train)\n",
    "        val_pred = ridge.predict(X_val_ready)\n",
    "        mse = float(np.mean(np.square(y_val - val_pred)))\n",
    "        if mse < best_ridge_val_mse:\n",
    "            best_ridge_val_mse = mse\n",
    "            best_ridge_alpha = float(alpha)\n",
    "            best_ridge_model = ridge\n",
    "\n",
    "    ridge_pred = best_ridge_model.predict(X_test_ready) if best_ridge_model is not None else np.zeros_like(y_pred)\n",
    "    ridge_errors = y_test_np - ridge_pred\n",
    "    ridge_sse = float(np.square(ridge_errors).sum())\n",
    "    ridge_r2 = 1.0 - ridge_sse / tss_zero if tss_zero > 0 else float('nan')\n",
    "\n",
    "    test_slice = panel_df.loc[mask_test, ID_COLUMNS + ['obs_date']].copy()\n",
    "    test_slice['model_iteration'] = counter\n",
    "    test_slice['predicted_stock_ret'] = y_pred.astype(np.float32)\n",
    "    test_slice['actual_stock_ret'] = y_test_np.astype(np.float32)\n",
    "    test_slice['squared_error'] = np.square(errors).astype(np.float32)\n",
    "    test_slice['ridge_stock_ret'] = ridge_pred.astype(np.float32)\n",
    "    test_slice['ridge_squared_error'] = np.square(ridge_errors).astype(np.float32)\n",
    "    predictions_by_month.append(test_slice)\n",
    "\n",
    "    for (year_val, month_val), df_month in test_slice.groupby(['year', 'month'], sort=False):\n",
    "        year_int = int(year_val)\n",
    "        month_int = int(month_val)\n",
    "        dest = OUTPUT_ROOT / f\"year={year_int}\" / f\"month={month_int}\"\n",
    "        dest.mkdir(parents=True, exist_ok=True)\n",
    "        df_month.to_parquet(dest / 'part-0.parquet', index=False)\n",
    "\n",
    "    train_months = panel_df.loc[mask_train, 'obs_date'].nunique()\n",
    "    val_months = panel_df.loc[mask_val, 'obs_date'].nunique()\n",
    "    test_months = panel_df.loc[mask_test, 'obs_date'].nunique()\n",
    "\n",
    "    window_summaries.append({\n",
    "        'iteration': counter,\n",
    "        'train_rows': int(mask_train.sum()),\n",
    "        'val_rows': int(mask_val.sum()),\n",
    "        'test_rows': int(mask_test.sum()),\n",
    "        'train_months': int(train_months),\n",
    "        'val_months': int(val_months),\n",
    "        'test_months': int(test_months),\n",
    "        'train_end': (train_end - MonthEnd(1)).date(),\n",
    "        'val_end': (val_end - MonthEnd(1)).date(),\n",
    "        'test_start': test_start.date(),\n",
    "        'test_end': (test_end - MonthEnd(1)).date(),\n",
    "        'pca_components': pca_components,\n",
    "        'pca_variance': pca_var,\n",
    "        'xgb_best_iteration': int(best_model.best_iteration) if getattr(best_model, 'best_iteration', None) is not None else None,\n",
    "        'xgb_val_rmse': best_val_rmse,\n",
    "        'xgb_params': best_params,\n",
    "        'xgb_oos_r2': r2_oos,\n",
    "        'ridge_alpha': best_ridge_alpha,\n",
    "        'ridge_val_mse': best_ridge_val_mse,\n",
    "        'ridge_oos_r2': ridge_r2,\n",
    "        'xgb_sse': sse,\n",
    "        'ridge_sse': ridge_sse,\n",
    "        'tss_zero': tss_zero,\n",
    "    })\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "window_summary_df = pd.DataFrame(window_summaries)\n",
    "print(f\"Completed {len(window_summary_df)} expanding-window fits.\")\n",
    "window_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ca17c62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T19:31:22.857352Z",
     "iopub.status.busy": "2025-10-05T19:31:22.857144Z",
     "iopub.status.idle": "2025-10-05T19:31:23.132259Z",
     "shell.execute_reply": "2025-10-05T19:31:23.131633Z",
     "shell.execute_reply.started": "2025-10-05T19:31:22.857336Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOS coverage: 2015-01-31 to 2025-06-30\n",
      "Total test observations: 3,489,521\n",
      "Overall XGBoost OOS R^2 (Gu et al. 2020): 0.0000003678\n",
      "Overall Ridge OOS R^2 (Gu et al. 2020): 0.0000014713\n",
      "First five monthly OOS R^2 values:\n",
      "    obs_date  xgb_oos_r2  ridge_oos_r2\n",
      "0 2015-01-31   -0.000161     -0.000039\n",
      "1 2015-02-28    0.000005      0.000009\n",
      "2 2015-03-31    0.007644      0.005483\n",
      "3 2015-04-30    0.025554      0.032209\n",
      "4 2015-05-31    0.010401      0.007181\n",
      "Worst five XGBoost months:\n",
      "      obs_date  xgb_oos_r2  ridge_oos_r2\n",
      "122 2025-03-31   -0.837433     -0.093819\n",
      "105 2023-10-31   -0.297923     -0.035605\n",
      "87  2022-04-30   -0.221091     -0.033536\n",
      "89  2022-06-30   -0.192514     -0.047294\n",
      "76  2021-05-31   -0.120968      0.001192\n",
      "Worst five Ridge months:\n",
      "      obs_date  xgb_oos_r2  ridge_oos_r2\n",
      "84  2022-01-31   -0.095201     -0.113144\n",
      "122 2025-03-31   -0.837433     -0.093819\n",
      "111 2024-04-30   -0.043427     -0.083051\n",
      "113 2024-06-30   -0.031305     -0.067985\n",
      "45  2018-10-31   -0.085328     -0.065387\n",
      "Sample predictions:\n",
      "Predictions written to /kaggle/working/oos_preds_pca\n",
      "PCA component summary (first five windows):\n",
      "   iteration  pca_components  pca_variance\n",
      "0          0              27      0.952606\n",
      "1          1              27      0.952901\n",
      "2          2              27      0.953052\n",
      "3          3              27      0.953195\n",
      "4          4              27      0.953174\n",
      "Average components retained: 27.00, average variance captured: 0.9534\n"
     ]
    }
   ],
   "source": [
    "if predictions_by_month:\n",
    "    oos_predictions = pd.concat(predictions_by_month, ignore_index=True)\n",
    "    oos_predictions['actual_squared'] = np.square(oos_predictions['actual_stock_ret']).astype(np.float32)\n",
    "    overall_sse = float(oos_predictions['squared_error'].sum())\n",
    "    overall_ridge_sse = float(oos_predictions['ridge_squared_error'].sum())\n",
    "    overall_tss_zero = float(oos_predictions['actual_squared'].sum())\n",
    "    overall_r2 = 1.0 - overall_sse / overall_tss_zero if overall_tss_zero > 0 else float('nan')\n",
    "    overall_ridge_r2 = 1.0 - overall_ridge_sse / overall_tss_zero if overall_tss_zero > 0 else float('nan')\n",
    "    print(f\"OOS coverage: {oos_predictions['obs_date'].min().date()} to {oos_predictions['obs_date'].max().date()}\")\n",
    "    print(f\"Total test observations: {len(oos_predictions):,}\")\n",
    "    print(f\"Overall XGBoost OOS R^2 (Gu et al. 2020): {overall_r2:.10f}\")\n",
    "    print(f\"Overall Ridge OOS R^2 (Gu et al. 2020): {overall_ridge_r2:.10f}\")\n",
    "\n",
    "    monthly_stats = oos_predictions.groupby('obs_date', as_index=False).agg(\n",
    "        sse=('squared_error', 'sum'),\n",
    "        ridge_sse=('ridge_squared_error', 'sum'),\n",
    "        tss_zero=('actual_squared', 'sum'),\n",
    "    )\n",
    "    numer = monthly_stats['sse'].to_numpy(dtype=np.float64)\n",
    "    numer_ridge = monthly_stats['ridge_sse'].to_numpy(dtype=np.float64)\n",
    "    denom = monthly_stats['tss_zero'].to_numpy(dtype=np.float64)\n",
    "    monthly_stats['xgb_oos_r2'] = 1.0 - np.divide(\n",
    "        numer,\n",
    "        denom,\n",
    "        out=np.full(numer.shape, np.nan, dtype=np.float64),\n",
    "        where=denom > 0,\n",
    "    )\n",
    "    monthly_stats['ridge_oos_r2'] = 1.0 - np.divide(\n",
    "        numer_ridge,\n",
    "        denom,\n",
    "        out=np.full(numer_ridge.shape, np.nan, dtype=np.float64),\n",
    "        where=denom > 0,\n",
    "    )\n",
    "\n",
    "    monthly_r2 = monthly_stats[['obs_date', 'xgb_oos_r2', 'ridge_oos_r2']]\n",
    "    print('First five monthly OOS R^2 values:')\n",
    "    print(monthly_r2.head())\n",
    "    print('Worst five XGBoost months:')\n",
    "    print(monthly_r2.nsmallest(5, 'xgb_oos_r2'))\n",
    "    print('Worst five Ridge months:')\n",
    "    print(monthly_r2.nsmallest(5, 'ridge_oos_r2'))\n",
    "    print('Sample predictions:')\n",
    "    oos_predictions.head()\n",
    "\n",
    "    print(f\"Predictions written to {OUTPUT_ROOT.resolve()}\")\n",
    "\n",
    "    if 'window_summary_df' in globals() and not window_summary_df.empty:\n",
    "        print('PCA component summary (first five windows):')\n",
    "        print(window_summary_df[['iteration', 'pca_components', 'pca_variance']].head())\n",
    "        avg_components = window_summary_df['pca_components'].mean()\n",
    "        avg_var = window_summary_df['pca_variance'].mean()\n",
    "        print(f'Average components retained: {avg_components:.2f}, average variance captured: {avg_var:.4f}')\n",
    "else:\n",
    "    print('No out-of-sample predictions were generated.')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8347460,
     "sourceId": 13172823,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8347505,
     "sourceId": 13172888,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8354940,
     "sourceId": 13184163,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
