{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38371cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.dataset as ds\n",
    "import xgboost as xgb\n",
    "\n",
    "# config\n",
    "DEVICE = \"cuda\" # set to \"cpu\" if needed\n",
    "ROOT = Path(\"processed_data2\")\n",
    "TARGET = \"stock_ret\"\n",
    "ID_COLS = [\"gvkey\",\"iid\",\"excntry\"]\n",
    "NON_FEATURES = {\"id\",\"date\",\"gvkey\",\"iid\",\"excntry\",\"year\",\"month\",\"char_date\",\"char_eom\",\"ret_eom\",\"stock_ret\",\"prc\",\"y\",\"m\"}\n",
    "TRAIN_START = 2005\n",
    "OOS_START, OOS_END = 2015, 2025\n",
    "LOG_DIR = Path(\"train_logs\")\n",
    "LOG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# tuning config\n",
    "random.seed(0)\n",
    "TUNE_YEAR = 2018\n",
    "N_TRIALS = 20\n",
    "WARM_ROUNDS = 200\n",
    "EARLY_STOP = 30\n",
    "PRUNE_MARGIN = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16660456",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Write to non-features.txt every row in column_names.txt but not in factor_char_list.csv\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mnon-features.txt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcols\u001b[49m:\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m factor_chars:\n\u001b[32m      8\u001b[39m             out.write(col + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'cols' is not defined"
     ]
    }
   ],
   "source": [
    "# Read factor_char_list.csv into a set\n",
    "factor_chars = set(pd.read_csv(\"factor_char_list.csv\", header=None).iloc[:,0].astype(str).str.strip())\n",
    "\n",
    "# Write to non-features.txt every row in column_names.txt but not in factor_char_list.csv\n",
    "with open(\"non-features.txt\", \"w\") as out:\n",
    "    for col in cols:\n",
    "        if col not in factor_chars:\n",
    "            out.write(col + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ae299dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(TRAIN_START, OOS_END + 1):\n",
    "    for month in months_in(year):\n",
    "        df = pd.read_parquet(ROOT / f\"y={year}\" / f\"m={month}\" / \"part-0.parquet\")\n",
    "        idx = df['stock_ret'].abs().idxmax()\n",
    "        val = df.loc[idx, 'stock_ret']\n",
    "        print(f\"Year {year} Month {month}: max magnitude stock_ret = {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9368677",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"column_names.txt\",\"r\") as f:\n",
    "    cols = [c.strip() for c in f if c.strip()]\n",
    "    FEATURES = [c for c in cols if c not in NON_FEATURES]\n",
    "\n",
    "def dataset():\n",
    "    return ds.dataset(str(ROOT), format=\"parquet\", partitioning=\"hive\")\n",
    "\n",
    "def months_in(year):\n",
    "    base = ROOT / f\"y={year}\"\n",
    "    if not base.exists():\n",
    "        return []\n",
    "    return [m for m in range(1,13) if (base / f\"m={m}\").exists()]\n",
    "\n",
    "class ArrowMonthIter(xgb.core.DataIter):\n",
    "    def __init__(self, y_start, y_end, features, target, batch_size=131072):\n",
    "        super().__init__()\n",
    "        self.y_start = y_start\n",
    "        self.y_end = y_end\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.batch_size = batch_size\n",
    "        self._plan = [(y, m) for y in range(y_start, y_end+1) for m in months_in(y)]\n",
    "        self._d = None\n",
    "        self._idx = 0\n",
    "        self._batches = None\n",
    "    def reset(self):\n",
    "        self._d = dataset()\n",
    "        self._idx = 0\n",
    "        self._batches = None\n",
    "    def next(self, input_data):\n",
    "        while True:\n",
    "            if self._batches is None:\n",
    "                if self._idx >= len(self._plan):\n",
    "                    return 0\n",
    "                y, m = self._plan[self._idx]\n",
    "                self._idx += 1\n",
    "                flt = (ds.field(\"y\")==y) & (ds.field(\"m\")==m)\n",
    "                cols = self.features + [self.target]\n",
    "                scn = self._d.scanner(columns=cols, filter=flt, batch_size=self.batch_size)\n",
    "                self._batches = iter(scn.to_batches())\n",
    "            try:\n",
    "                rb = next(self._batches)\n",
    "            except StopIteration:\n",
    "                self._batches = None\n",
    "                continue\n",
    "            X = np.column_stack([rb.column(n).to_numpy(zero_copy_only=False) for n in self.features]).astype(np.float32, copy=False)\n",
    "            y = rb.column(self.target).to_numpy(zero_copy_only=False).astype(np.float32, copy=False)\n",
    "            input_data(data=X, label=y)\n",
    "            return 1\n",
    "\n",
    "def _build_dmats(train_end, val_start, val_end, max_bin):\n",
    "    it_tr = ArrowMonthIter(TRAIN_START, train_end, FEATURES, TARGET)\n",
    "    it_va = ArrowMonthIter(val_start,   val_end,   FEATURES, TARGET)\n",
    "    dtr = xgb.QuantileDMatrix(it_tr, missing=np.nan, max_bin=max_bin)\n",
    "    dva = xgb.QuantileDMatrix(it_va, ref=dtr, missing=np.nan, max_bin=max_bin)\n",
    "    return dtr, dva\n",
    "\n",
    "def _train_until(dtr, dva, params, max_rounds):\n",
    "    bst = xgb.train(params, dtr, num_boost_round=max_rounds, evals=[(dva,\"val\")], early_stopping_rounds=EARLY_STOP, verbose_eval=False)\n",
    "    rmse = float(bst.best_score)\n",
    "    best_it = bst.best_iteration if bst.best_iteration is not None else max_rounds - 1\n",
    "    yhat = bst.predict(dva, iteration_range=(0, best_it + 1))\n",
    "    sigma_pred = float(np.std(yhat))\n",
    "    return bst, rmse, best_it, sigma_pred\n",
    "\n",
    "def tune_once():\n",
    "    y = TUNE_YEAR\n",
    "    base = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"device\": DEVICE,\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"lambda\": 5.0,\n",
    "        \"alpha\": 0.0,\n",
    "        \"seed\": 0,\n",
    "        \"nthread\": -1,\n",
    "        \"colsample_bytree\": 0.8\n",
    "    }\n",
    "\n",
    "    mb_candidates = [256, 512]\n",
    "    mcw_candidates = [1, 20]\n",
    "    depths = [4, 6]\n",
    "    etas = [0.03, 0.05]\n",
    "    subs = [0.7, 0.9]\n",
    "\n",
    "    trials = [{\n",
    "        \"max_depth\": random.choice(depths),\n",
    "        \"eta\": random.choice(etas),\n",
    "        \"subsample\": random.choice(subs),\n",
    "        \"min_child_weight\": random.choice(mcw_candidates),\n",
    "        \"max_bin\": random.choice(mb_candidates)\n",
    "    } for _ in range(N_TRIALS)]\n",
    "\n",
    "    dmat_cache = {}\n",
    "    def get_dmats(mb):\n",
    "        if mb not in dmat_cache:\n",
    "            dmat_cache[mb] = _build_dmats(y-3, y-2, y-1, mb)\n",
    "        return dmat_cache[mb]\n",
    "\n",
    "    best_rmse = float(\"inf\")\n",
    "    chosen = None\n",
    "    for t in trials:\n",
    "        params = dict(base, **t)\n",
    "        dtr, dva = get_dmats(t[\"max_bin\"])\n",
    "        _, warm_rmse, _, _ = _train_until(dtr, dva, params, WARM_ROUNDS)\n",
    "        if chosen is not None and warm_rmse > best_rmse * (1.0 + PRUNE_MARGIN):\n",
    "            continue\n",
    "        bst, rmse, best_it, sig = _train_until(dtr, dva, params, 2000)\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            chosen = {\"params\": params, \"best_iteration\": best_it, \"sigma_pred_val\": sig}\n",
    "\n",
    "    if chosen is None:\n",
    "        chosen = {\"params\": dict(base, max_depth=6, eta=0.05, subsample=0.9, min_child_weight=20, max_bin=256),\n",
    "                  \"best_iteration\": 1000, \"sigma_pred_val\": None}\n",
    "\n",
    "    (LOG_DIR / \"global_best.json\").write_text(json.dumps(chosen, indent=2))\n",
    "    print(\"tuned_params:\", chosen)\n",
    "    return chosen\n",
    "\n",
    "def get_best_params():\n",
    "    p = LOG_DIR / \"global_best.json\"\n",
    "    if p.exists():\n",
    "        return json.loads(p.read_text())\n",
    "    return tune_once()\n",
    "\n",
    "def fit_for_oos_year(oos_year):\n",
    "    best = get_best_params()\n",
    "    mb = best[\"params\"][\"max_bin\"]\n",
    "    dtr, dva = _build_dmats(oos_year - 3, oos_year - 2, oos_year - 1, mb)\n",
    "    params = best[\"params\"]\n",
    "    bst = xgb.train(params, dtr, num_boost_round=5000, evals=[(dva,\"val\")],\n",
    "                    early_stopping_rounds=EARLY_STOP, verbose_eval=False)\n",
    "    return bst\n",
    "\n",
    "def predict_year(bst, year, out_root: Path):\n",
    "    out_root.mkdir(exist_ok=True)\n",
    "    for m in months_in(year):\n",
    "        d = dataset()\n",
    "        flt = (ds.field(\"y\")==year) & (ds.field(\"m\")==m)\n",
    "        cols = FEATURES + ID_COLS + [\"y\",\"m\"]\n",
    "        rbatches = d.scanner(columns=cols, filter=flt, batch_size=131072).to_batches()\n",
    "        rows = []\n",
    "        preds = []\n",
    "        for rb in rbatches:\n",
    "            X = np.column_stack([rb.column(name).to_numpy(zero_copy_only=False) for name in FEATURES]).astype(np.float32, copy=False)\n",
    "            dm = xgb.DMatrix(X, missing=np.nan)\n",
    "            p = bst.predict(dm)\n",
    "            ids = {k: rb.column(k).to_numpy(zero_copy_only=False) for k in (ID_COLS + [\"y\",\"m\"])}\n",
    "            rows.append(ids)\n",
    "            preds.append(p.astype(np.float32, copy=False))\n",
    "        if not rows:\n",
    "            continue\n",
    "        ids = {k: np.concatenate([r[k] for r in rows]) for k in rows[0].keys()}\n",
    "        out = pd.DataFrame(ids)\n",
    "        out[\"pred_ret_t1\"] = np.concatenate(preds)\n",
    "        out = out.groupby(ID_COLS + [\"y\",\"m\"], as_index=False)[\"pred_ret_t1\"].mean()\n",
    "        sigma_month = float(out[\"pred_ret_t1\"].std())\n",
    "        print(f\"year {year} m {m} sigma_pred_oos {sigma_month:.6f}\")\n",
    "        pdir = out_root / f\"y={int(year)}\" / f\"m={int(m)}\"\n",
    "        pdir.mkdir(parents=True, exist_ok=True)\n",
    "        out.to_parquet(pdir / \"part-0.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd631aeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowTypeError",
     "evalue": "Unable to merge: Field month has incompatible types: int16 vs int32",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArrowTypeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(OOS_START, OOS_END+\u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     bst = \u001b[43mfit_for_oos_year\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     predict_year(bst, year, Path(\u001b[33m\"\u001b[39m\u001b[33moos_preds\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myear \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: prediction pass done\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 128\u001b[39m, in \u001b[36mfit_for_oos_year\u001b[39m\u001b[34m(oos_year)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_for_oos_year\u001b[39m(oos_year):\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     best = \u001b[43mget_best_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m     mb = best[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmax_bin\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    130\u001b[39m     dtr, dva = _build_dmats(oos_year - \u001b[32m3\u001b[39m, oos_year - \u001b[32m2\u001b[39m, oos_year - \u001b[32m1\u001b[39m, mb)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 125\u001b[39m, in \u001b[36mget_best_params\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p.exists():\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json.loads(p.read_text())\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtune_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mtune_once\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m trials:\n\u001b[32m    103\u001b[39m     params = \u001b[38;5;28mdict\u001b[39m(base, **t)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     dtr, dva = \u001b[43mget_dmats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_bin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m     _, warm_rmse, _, _ = _train_until(dtr, dva, params, WARM_ROUNDS)\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chosen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m warm_rmse > best_rmse * (\u001b[32m1.0\u001b[39m + PRUNE_MARGIN):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 97\u001b[39m, in \u001b[36mtune_once.<locals>.get_dmats\u001b[39m\u001b[34m(mb)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_dmats\u001b[39m(mb):\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mb \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dmat_cache:\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m         dmat_cache[mb] = \u001b[43m_build_dmats\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dmat_cache[mb]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36m_build_dmats\u001b[39m\u001b[34m(train_end, val_start, val_end, max_bin)\u001b[39m\n\u001b[32m     52\u001b[39m it_tr = ArrowMonthIter(TRAIN_START, train_end, FEATURES, TARGET)\n\u001b[32m     53\u001b[39m it_va = ArrowMonthIter(val_start,   val_end,   FEATURES, TARGET)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m dtr = \u001b[43mxgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mQuantileDMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_bin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m dva = xgb.QuantileDMatrix(it_va, ref=dtr, missing=np.nan, max_bin=max_bin)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dtr, dva\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/FIAM/.venv/lib/python3.13/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/FIAM/.venv/lib/python3.13/site-packages/xgboost/core.py:1614\u001b[39m, in \u001b[36mQuantileDMatrix.__init__\u001b[39m\u001b[34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, max_quantile_batches, data_split_mode)\u001b[39m\n\u001b[32m   1594\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   1595\u001b[39m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1596\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   (...)\u001b[39m\u001b[32m   1607\u001b[39m         )\n\u001b[32m   1608\u001b[39m     ):\n\u001b[32m   1609\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1610\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mIf data iterator is used as input, data like label should be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1611\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mspecified as batch argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1612\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1614\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1621\u001b[39m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1624\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_quantile_blocks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_quantile_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/FIAM/.venv/lib/python3.13/site-packages/xgboost/core.py:1678\u001b[39m, in \u001b[36mQuantileDMatrix._init\u001b[39m\u001b[34m(self, data, ref, enable_categorical, max_quantile_blocks, **meta)\u001b[39m\n\u001b[32m   1663\u001b[39m config = make_jcargs(\n\u001b[32m   1664\u001b[39m     nthread=\u001b[38;5;28mself\u001b[39m.nthread,\n\u001b[32m   1665\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1666\u001b[39m     max_bin=\u001b[38;5;28mself\u001b[39m.max_bin,\n\u001b[32m   1667\u001b[39m     max_quantile_blocks=max_quantile_blocks,\n\u001b[32m   1668\u001b[39m )\n\u001b[32m   1669\u001b[39m ret = _LIB.XGQuantileDMatrixCreateFromCallback(\n\u001b[32m   1670\u001b[39m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1671\u001b[39m     it.proxy.handle,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1676\u001b[39m     ctypes.byref(handle),\n\u001b[32m   1677\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1678\u001b[39m \u001b[43mit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1679\u001b[39m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[32m   1680\u001b[39m _check_call(ret)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/FIAM/.venv/lib/python3.13/site-packages/xgboost/core.py:572\u001b[39m, in \u001b[36mDataIter.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    570\u001b[39m exc = \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    571\u001b[39m \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m572\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/FIAM/.venv/lib/python3.13/site-packages/xgboost/core.py:553\u001b[39m, in \u001b[36mDataIter._handle_exception\u001b[39m\u001b[34m(self, fn, dft_ret)\u001b[39m\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dft_ret\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    555\u001b[39m     \u001b[38;5;66;03m# Defer the exception in order to return 0 and stop the iteration.\u001b[39;00m\n\u001b[32m    556\u001b[39m     \u001b[38;5;66;03m# Exception inside a ctype callback function has no effect except\u001b[39;00m\n\u001b[32m    557\u001b[39m     \u001b[38;5;66;03m# for printing to stderr (doesn't stop the execution).\u001b[39;00m\n\u001b[32m    558\u001b[39m     tb = sys.exc_info()[\u001b[32m2\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mArrowMonthIter.reset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28mself\u001b[39m._d = \u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mself\u001b[39m._idx = \u001b[32m0\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mself\u001b[39m._batches = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mdataset\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdataset\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mROOT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhive\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/FIAM/.venv/lib/python3.13/site-packages/pyarrow/dataset.py:790\u001b[39m, in \u001b[36mdataset\u001b[39m\u001b[34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[39m\n\u001b[32m    779\u001b[39m kwargs = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    780\u001b[39m     schema=schema,\n\u001b[32m    781\u001b[39m     filesystem=filesystem,\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     selector_ignore_prefixes=ignore_prefixes\n\u001b[32m    787\u001b[39m )\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_path_like(source):\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_filesystem_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[32m    792\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_path_like(elem) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, FileInfo) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m source):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/FIAM/.venv/lib/python3.13/site-packages/pyarrow/dataset.py:482\u001b[39m, in \u001b[36m_filesystem_dataset\u001b[39m\u001b[34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[39m\n\u001b[32m    474\u001b[39m options = FileSystemFactoryOptions(\n\u001b[32m    475\u001b[39m     partitioning=partitioning,\n\u001b[32m    476\u001b[39m     partition_base_dir=partition_base_dir,\n\u001b[32m    477\u001b[39m     exclude_invalid_files=exclude_invalid_files,\n\u001b[32m    478\u001b[39m     selector_ignore_prefixes=selector_ignore_prefixes\n\u001b[32m    479\u001b[39m )\n\u001b[32m    480\u001b[39m factory = FileSystemDatasetFactory(fs, paths_or_selector, \u001b[38;5;28mformat\u001b[39m, options)\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfactory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/FIAM/.venv/lib/python3.13/site-packages/pyarrow/_dataset.pyx:3196\u001b[39m, in \u001b[36mpyarrow._dataset.DatasetFactory.finish\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/FIAM/.venv/lib/python3.13/site-packages/pyarrow/error.pxi:155\u001b[39m, in \u001b[36mpyarrow.lib.pyarrow_internal_check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Coding/FIAM/.venv/lib/python3.13/site-packages/pyarrow/error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mArrowTypeError\u001b[39m: Unable to merge: Field month has incompatible types: int16 vs int32"
     ]
    }
   ],
   "source": [
    "for year in range(OOS_START, OOS_END+1):\n",
    "    bst = fit_for_oos_year(year)\n",
    "    predict_year(bst, year, Path(\"oos_preds\"))\n",
    "    print(f\"year {year}: prediction pass done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
